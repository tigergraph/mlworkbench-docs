= ML Workbench for an Existing Jupyter Server

If you have a running Jupyter lab server or you are using the Jupyter lab on Microsoft Azure,  AWS Sagemaker, or Google Vertex AI, you can still take advantage of our ML Workbench by installing the Python package.

You can choose to install on the base kernel or using a Conda environment.

== Base kernel installation

From JupyterLab, open a new terminal and run the following command to install pyTigerGraph:
[source,console]
----
pip install pyTigerGraph[gds]
----

== Conda environment installation

. Run the following command to install our Python environment:
+
[tabs]
====
CPU::
+
--
[source.wrap,console]
----
conda env create -f https://raw.githubusercontent.com/TigerGraph-DevLabs/mlworkbench-docs/main/conda_envs/tigergraph-torch-cpu.yml
----
--
GPU::
+
--
[source.wrap,console]
----
conda env create -f https://raw.githubusercontent.com/TigerGraph-DevLabs/mlworkbench-docs/main/conda_envs/tigergraph-torch-gpu.yml
----
--
====
+

. Run `source activate tigergraph-torch-cpu` or `source activate tigergraph-torch-gpu` to activate your environment depending on if you installed a CPU or GPU environment.
. Run the following command to install the Python kernel:
+
[tabs]
====
CPU::
+
--
[.wrap,console]
----
python -m ipykernel install --user --name tigergraph-torch-cpu --display-name "TigerGraph Pytorch (cpu)"
----
--
GPU::
+
--
[.wrap,console]
----
python -m ipykernel install --user --name tigergraph-torch-gpu --display-name "TigerGraph Pytorch (gpu)"
----
--
====

== Next steps

The next step after installation is xref:activate.adoc[activation].

After installation, go to our xref:tutorials:index.adoc[] section.

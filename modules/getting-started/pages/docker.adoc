= Run ML Workbench from Docker

This page walks you through running the TigerGraph ML Workbench in a Docker container.
TigerGraph provides two docker images for this purpose:

* The `tigergraphml/sandbox` image.
This image has both the Workbench and TigerGraph Server 3.5.
Graph Data Processing Service (GDPS) is already installed on the server.
The sample "Cora" data set is also preloaded into the image.
* The `tigergraphml/mlworkbench` image.
This image only contains the ML Workbench.

[#_run_workbench_and_tigergraph_server_in_one_container]
== Run Workbench and TigerGraph server in one container
To help you get started quickly, we provide a “sandbox” docker image that has the TigerGraph database, GDPS, and ML Workbench pre-installed.
The “Cora” dataset used for tutorials is also preloaded into the database.

=== Prerequisites
* You machine needs to meet the xref:tigergraph-server:installation:hw-and-sw-requirements.adoc[].
** Make sure you are allocating enough CPU and memory to your Docker containers.
It is recommended that you allocate at least 8 CPUs and 16 GB of memory to your Docker containers.
* Docker is running on your machine.

=== Procedure

Run the following command to pull the Workbench image, bind ports, map a shared data folder, and start a container from the image

[.wrap,console]
----
docker run -it -p 14022:22 -p 8000:8000 -p 8888:8888 -p 9000:9000 -p 14240:14240  --name tgsandbox --ulimit nofile=1000000:1000000 -v ~/tgsandbox:/home/tigergraph/tgsandbox tigergraphml/sandbox
----

Here is a breakdown of the options in the docker run command above

* `-it`: run the container interactively and allocate a pseudo-TTY.
* `-p`: map a port of the host (14022) to a port of the container (22).
* `--name`: name of the container. Can be any name you like.
* `--ulimit`: the limit of number of open file descriptors per process.
* -v: mount a folder on the host (`~/tgsandbox`) to a folder in the container (`/home/tigergraph/tgsandbox`).
This allows you to keep your files after the container is removed.
If you are using Windows, change the path using Windows file system conventions.
For example, `c:\tgsandbox instead of ~/tgsandbox`.

=== Video walk-through
Here is a video walk-through of running the sandbox image:

video::7vnxNPWxoVQ[youtube,width=600,height=400]


== Run Workbench by itself
You can the Workbench by itself in a Docker container, and xref:connect-to-server.adoc[connect to a TigerGraph server] later.

[NOTE]
====
If the TigerGraph server you are connecting to is also run in a container, running the ML workbench by itself in a container on the same machine will produce communication issues between the workbench and the server.

If you want to run both the ML workbench and the TigerGraph in Docker containers on the same machine, replace the Docker image with the following:
====

=== Prerequisites
* Docker Desktop is installed on your computer and running on your machine.

=== Procedure
. Run the following command to pull the Workbench image, bind ports, map a shared data folder, and start a container from the image:
+
[.wrap,console]
----
$ docker run --name mlworkbench -it -p 8888:8888 -v ~/tmp:/home/tigergraph tigergraphml/mlworkbench <1>
----
. Visit http://localhost:8888 in your browser to access the Jupyter lab server.

== Next steps

* xref:connect-to-server.adoc[Connect your Workbench to a TigerGraph server] (Skip this step if you are using the sandbox image)
* xref:tutorials:index.adoc#_train_your_first_model[Train your first model].



= Integrate ML Workbench with Azure ML
:sectnums:
:description: Instructions for integrating ML Workbench with Azure ML
:experimental:

This guide walks you through integrating the ML Workbench with a compute instance on Azure Machine Learning (AML).

== Prerequisites
* An Azure Machine Learning Workspace with a running compute instance.

== Procedure
. From Azure ML Studio, find your compute instance, and open the Jupyter Lab instance running on it.
. Open a terminal in the Jupyter Lab instance.
From the terminal, run `pip install tigergraph_mlworkbench`.
This installs the ML Workbench JupyterLab extension.
include::partial$install-kernel.adoc[]
. Install the Tigergraph Pytorch kernel in JupyterLab by running the following command in the terminal:
+
[.wrap,console]
----
conda activate tigergraph-torch-gpu && pip install ipykernel && python -m ipykernel install --user --name tigergraph-torch-gpu --display-name "TigerGraph Pytorch (gpu)"
----

Once installation finishes, refresh your browser.
You should see a small TigerGraph logo on the very left navigation bar and a new Python kernel called TigerGraph Pytorch on the launch page.
You now have successfully installed the TigerGraph ML Workbench on an Azure Machine Learning compute instance.

== Next steps
* With the ML Workbench JupyterLab extension and the `tigergraph-torch` kernel installed, the next step is to xref:deploy-gdps.adoc[deploy GDPS] on your TigerGraph instance so the Workbench can communicate with your TigerGraph database.
* You can connect to your Azure compute instance from VS Code if you have SSH access to the compute instance.
See https://docs.microsoft.com/en-us/azure/machine-learning/how-to-set-up-vs-code-remote?tabs=studio[Connect to an Azure Machine Learning compute instance in Visual Studio Code (preview)]


